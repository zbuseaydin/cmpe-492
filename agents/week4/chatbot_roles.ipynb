{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fe5dd3-aea8-4d77-a552-5f526c49e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatCohere(model=\"command-r-plus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981365ac-5184-4464-9cc5-513a6655fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5cbb388-2765-40d2-85fd-ff41903a5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "expert_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"{system_prompt}\"), (\"user\", \"{user_prompt}\")]\n",
    ")\n",
    "expert_chain = expert_prompt_template | llm | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77b7d6d-0f9a-44f1-aaf8-724348c7326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x121bfaf90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "# add \"legal consultant\"\n",
    "#expert_system_prompts = {\n",
    "#    \"technical assistant\": \"You are an expert in technical issues and help with coding or technical problem solving.\",\n",
    "#    \"financial advisor\": \"You provide advice and insights on financial matters, including budgeting, investment, and expenses.\", \n",
    "#    \"health expert\": \"You offer guidance on health, nutrition, and fitness-related topics.\", \n",
    "#    \"mental health guide\": \"You offer guidance on mental health, and psychology-related topics.\", \n",
    "#    \"travel guide\": \"You provide travel tips, itinerary suggestions, and destination recommendations.\"\n",
    "#}\n",
    "\n",
    "@tool\n",
    "def generate_technical_response(user_prompt: str) -> str:\n",
    "    \"\"\"Generates response\n",
    "    \n",
    "    Args:\n",
    "        inp: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    prompt = {\"system_prompt\": \"You are an expert in technical issues and help with coding or technical problem solving.\", \"user_prompt\": user_prompt}\n",
    "    response = expert_chain.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "@tool\n",
    "def generate_financial_response(user_prompt: str) -> str:\n",
    "    \"\"\"Generates response\n",
    "    \n",
    "    Args:\n",
    "        inp: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    prompt = {\"system_prompt\": \"You provide advice and insights on financial matters, including budgeting, investment, and expenses.\", \"user_prompt\": user_prompt}\n",
    "    response = expert_chain.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "@tool\n",
    "def generate_health_response(user_prompt: str) -> str:\n",
    "    \"\"\"Generates response\n",
    "    \n",
    "    Args:\n",
    "        inp: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    prompt = {\"system_prompt\": \"You offer guidance on health, nutrition, and fitness-related topics.\", \"user_prompt\": user_prompt}\n",
    "    response = expert_chain.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "@tool\n",
    "def generate_mental_health_response(user_prompt: str) -> str:\n",
    "    \"\"\"Generates response\n",
    "    \n",
    "    Args:\n",
    "        inp: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    prompt = {\"system_prompt\": \"You offer guidance on mental health, and psychology-related topics.\", \"user_prompt\": user_prompt}\n",
    "    response = expert_chain.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "@tool\n",
    "def generate_travel_response(user_prompt: str) -> str:\n",
    "    \"\"\"Generates response\n",
    "    \n",
    "    Args:\n",
    "        inp: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    prompt = {\"system_prompt\": \"You provide travel tips, itinerary suggestions, and destination recommendations.\", \"user_prompt\": user_prompt}\n",
    "    response = expert_chain.invoke(prompt)\n",
    "    return response\n",
    "    \n",
    "\n",
    "# add \"legal consultant\"\n",
    "members = [\"Technical Assistant\", \"Financial Advisor\", \"Health Expert\", \"Mental Health Guide\", \"Travel Guide\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with passing the user question/requests to the relevant experts.\"\n",
    "    \" The experts are: {members}. Given the following user request,\"\n",
    "    \" respond with the expert to act next. The chosen expert should \"\n",
    "    \" respond with its results. Once you got a response from the expert, \"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    response = supervisor_chain.invoke(state)\n",
    "    return response\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "technical_agent = create_react_agent(llm, tools=[generate_technical_response])\n",
    "technical_node = functools.partial(agent_node, agent=technical_agent, name=\"Technical Assistant\")\n",
    "\n",
    "financial_agent = create_react_agent(llm, tools=[generate_financial_response])\n",
    "financial_node = functools.partial(agent_node, agent=financial_agent, name=\"Financial Advisor\")\n",
    "\n",
    "health_agent = create_react_agent(llm, tools=[generate_health_response])\n",
    "health_node = functools.partial(agent_node, agent=health_agent, name=\"Health Expert\")\n",
    "\n",
    "mental_health_agent = create_react_agent(llm, tools=[generate_mental_health_response])\n",
    "mental_health_node = functools.partial(agent_node, agent=mental_health_agent, name=\"Mental Health Guide\")\n",
    "\n",
    "travel_agent = create_react_agent(llm, tools=[generate_travel_response])\n",
    "travel_node = functools.partial(agent_node, agent=travel_agent, name=\"Travel Guide\")\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Technical Assistant\", technical_node)\n",
    "workflow.add_node(\"Financial Advisor\", financial_node)\n",
    "workflow.add_node(\"Health Expert\", health_node)\n",
    "workflow.add_node(\"Mental Health Guide\", mental_health_node)\n",
    "workflow.add_node(\"Travel Guide\", travel_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53f715a-8460-48d2-98dc-86f81942306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999c87aa-34c9-43e5-94a5-f8abeada6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image, display\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b7282-7aea-4445-8715-e744c4ec0114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER:  how can i manage my budget?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FINANCIAL ADVISOR: Here are some steps to help you manage your budget:\n",
      "\n",
      "1. Determine your income sources: Calculate your total income after taxes and deductions. This could include salary, investments, or any other sources.\n",
      "2. Track your expenses: List your fixed expenses (rent, utilities, insurance, etc.) and variable expenses (groceries, entertainment, dining out, etc.). Record every expense for at least a month to get an accurate picture.\n",
      "3. Set financial goals: Decide on short-term and long-term financial goals, such as saving for an emergency fund, paying off debt, or planning for retirement.\n",
      "4. Create a budget plan: Subtract your total expenses from your total income. If you're spending more than you earn, look for areas where you can cut back. Allocate your money wisely, ensuring you're saving or investing a portion while also covering necessary expenses.\n",
      "5. Stick to your budget: Use budgeting tools or apps, automate your savings, practice conscious spending, and review your budget regularly to identify areas where you might be overspending.\n",
      "6. Build an emergency fund: Aim to save enough to cover at least three to six months' worth of living expenses in case of unexpected events.\n",
      "7. Pay off debt: Create a plan to pay off any high-interest debt, such as credit cards.\n",
      "8. Seek help if needed: If you're struggling to manage your budget or have a large amount of debt, consider seeking help from a financial advisor or credit counsellor.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER:  thanks, i want to go to china. which places must i visit?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TRAVEL GUIDE: There are many places to visit in China, here are some of the most popular destinations:\n",
      "\n",
      "- The Great Wall of China\n",
      "- Forbidden City, Beijing\n",
      "- Terracotta Warriors, Xi'an\n",
      "- Shanghai\n",
      "- Hong Kong\n",
      "- Guilin and Yangshuo\n",
      "- Chengdu\n",
      "- Tibet\n",
      "- Zhangjiajie National Forest Park\n",
      "- Huangshan\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"USER: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [(\"user\", user_input)]}\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    for event in events:\n",
    "        if 'supervisor' in event and event['supervisor']:\n",
    "            if event['supervisor']['next'] == \"FINISH\":\n",
    "                print('-'*100)\n",
    "            else:\n",
    "                print(f\"{event['supervisor']['next'].upper()}: \", end=\"\")\n",
    "        else:\n",
    "            for agent_name, agent_data in event.items():\n",
    "                if not agent_data:\n",
    "                    print(\"Something went wrong.\")\n",
    "                    break\n",
    "                for message in agent_data[\"messages\"]:\n",
    "                    print(f\"{message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd74a59-a718-4e96-ae9f-187916b65154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
